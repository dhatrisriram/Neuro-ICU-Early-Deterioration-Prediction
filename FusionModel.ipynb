{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-08T14:00:56.437532Z",
     "iopub.status.busy": "2025-11-08T14:00:56.436965Z",
     "iopub.status.idle": "2025-11-08T14:01:03.462576Z",
     "shell.execute_reply": "2025-11-08T14:01:03.461841Z",
     "shell.execute_reply.started": "2025-11-08T14:00:56.437511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CELL 0: Setup & imports\n",
    "import os, random, math, time, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, brier_score_loss\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "INPUT_DIR = \"/kaggle/input/afml-proj\"\n",
    "WORK_DIR = \"/kaggle/working\"\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "STATIC_CSV = os.path.join(INPUT_DIR, \"static_features_final.csv\")\n",
    "TEMP_CSV   = os.path.join(INPUT_DIR, \"temporal_embeddings_predictions.csv\")\n",
    "CLIN_CSV   = os.path.join(INPUT_DIR, \"clinical_embeddings.csv\")\n",
    "RAD_CSV    = os.path.join(INPUT_DIR, \"radiology_embeddings.csv\")\n",
    "MERGED_PATH = os.path.join(WORK_DIR, \"merged_fusion_table.csv\")\n",
    "\n",
    "LABEL_COL = \"ventilation_within_12h\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:03.464252Z",
     "iopub.status.busy": "2025-11-08T14:01:03.463922Z",
     "iopub.status.idle": "2025-11-08T14:01:39.937869Z",
     "shell.execute_reply": "2025-11-08T14:01:39.936957Z",
     "shell.execute_reply.started": "2025-11-08T14:01:03.464234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /kaggle/input/afml-proj/static_features_final.csv\n",
      "Reading: /kaggle/input/afml-proj/temporal_embeddings_predictions.csv\n",
      "Reading: /kaggle/input/afml-proj/clinical_embeddings.csv\n",
      "Reading: /kaggle/input/afml-proj/radiology_embeddings.csv\n",
      "Scaled clinical embeddings to range roughly [-1,1] using max=9.64\n",
      "Merging temporal embeddings by stay_id ...\n",
      "Aggregating clinical embeddings per subject_id (mean pooling) ...\n",
      "Aggregating radiology embeddings per subject_id (mean pooling) ...\n",
      "Common subject_ids between static & radiology: 3486 / 8274\n",
      "Merged saved to: /kaggle/working/merged_fusion_table.csv shape: (8274, 1691)\n",
      "Detected counts â†’ temporal: 128 | clinical: 768 | radiology: 768\n",
      "Sample static cols: ['subject_id', 'stay_id', 'gender', 'first_careunit', 'ventilation_within_12h', 'subject_id_temp', '747_rad', '748_rad', '749_rad', '750_rad', '751_rad', '752_rad', '753_rad', '754_rad', '755_rad', '756_rad', '757_rad', '758_rad', '759_rad', '760_rad']\n",
      "Temporal embeddings present fraction: 0.957\n",
      "Clinical embeddings present fraction: 1.000\n",
      "Radiology embeddings present fraction: 0.646\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# CELL 1: Load and merge modality CSVs (with ID normalization & clinical scaling)\n",
    "# ======================================================\n",
    "\n",
    "def safe_read(path):\n",
    "    print(f\"Reading: {path}\")\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "# Remove old merged file so a fresh merge runs\n",
    "if os.path.exists(MERGED_PATH):\n",
    "    os.remove(MERGED_PATH)\n",
    "    print(f\"Deleted old merged table: {MERGED_PATH}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# If merged table already exists, reuse it\n",
    "# ------------------------------------------------------\n",
    "if os.path.exists(MERGED_PATH):\n",
    "    merged = safe_read(MERGED_PATH)\n",
    "    print(\"Loaded existing merged table:\", MERGED_PATH, merged.shape)\n",
    "\n",
    "else:\n",
    "    # ---- Load raw modality CSVs ----\n",
    "    static_df = safe_read(STATIC_CSV)\n",
    "    temp_df   = safe_read(TEMP_CSV)\n",
    "    clin_df   = safe_read(CLIN_CSV)\n",
    "    rad_df    = safe_read(RAD_CSV)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # ðŸ”§ Normalize IDs consistently across all sources\n",
    "    # ------------------------------------------------------\n",
    "    def normalize_id(col):\n",
    "        \"\"\"Standardize subject_id or stay_id across all sources.\"\"\"\n",
    "        return (\n",
    "            col.astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(\".0\", \"\", regex=False)\n",
    "            .str.lstrip(\"0\")\n",
    "            .str.replace(\" \", \"\", regex=False)\n",
    "        )\n",
    "\n",
    "    for d in (static_df, temp_df, clin_df, rad_df):\n",
    "        for id_col in ['subject_id', 'stay_id']:\n",
    "            if id_col in d.columns:\n",
    "                d[id_col] = normalize_id(d[id_col])\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # ðŸ§© Fix clinical embedding scale mismatch (normalize numeric columns)\n",
    "    # ------------------------------------------------------\n",
    "    if 'subject_id' in clin_df.columns:\n",
    "        numeric_cols = [c for c in clin_df.columns if np.issubdtype(clin_df[c].dtype, np.number)]\n",
    "        max_val = clin_df[numeric_cols].abs().max().max()\n",
    "        clin_df[numeric_cols] = clin_df[numeric_cols] / max_val\n",
    "        print(f\"Scaled clinical embeddings to range roughly [-1,1] using max={max_val:.2f}\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # ðŸ”— Merge all modalities\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    # ---- Merge stay-level temporal embeddings ----\n",
    "    print(\"Merging temporal embeddings by stay_id ...\")\n",
    "    merged = static_df.merge(temp_df, how='left', on='stay_id', suffixes=('', '_temp'))\n",
    "\n",
    "    # ---- Merge subject-level clinical embeddings ----\n",
    "    if 'subject_id' in clin_df.columns:\n",
    "        print(\"Aggregating clinical embeddings per subject_id (mean pooling) ...\")\n",
    "        clin_agg = clin_df.groupby('subject_id').mean(numeric_only=True).reset_index()\n",
    "        merged = merged.merge(clin_agg, how='left', on='subject_id', suffixes=('', '_clin'))\n",
    "\n",
    "    # ---- Merge subject-level radiology embeddings ----\n",
    "    if 'subject_id' in rad_df.columns:\n",
    "        print(\"Aggregating radiology embeddings per subject_id (mean pooling) ...\")\n",
    "        rad_agg = rad_df.groupby('subject_id').mean(numeric_only=True).reset_index()\n",
    "        merged = merged.merge(rad_agg, how='left', on='subject_id', suffixes=('', '_rad'))\n",
    "\n",
    "    # ---- Debug: check ID overlap ----\n",
    "    common_ids = len(set(static_df['subject_id']).intersection(set(rad_df['subject_id'])))\n",
    "    print(f\"Common subject_ids between static & radiology: {common_ids} / {len(static_df)}\")\n",
    "\n",
    "    merged.to_csv(MERGED_PATH, index=False)\n",
    "    print(f\"Merged saved to: {MERGED_PATH} shape: {merged.shape}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Detect embedding column blocks automatically\n",
    "# ------------------------------------------------------\n",
    "all_cols = merged.columns.tolist()\n",
    "\n",
    "temporal_cols = [c for c in all_cols if c.startswith('emb_') or \n",
    "                 c.startswith('trans_enc_emb_') or c.startswith('temporal_emb_')]\n",
    "if len(temporal_cols) == 0:\n",
    "    numeric_cols = [c for c in all_cols if np.issubdtype(merged[c].dtype, np.number)]\n",
    "    if len(numeric_cols) > 200:\n",
    "        temporal_cols = numeric_cols[-128:]\n",
    "\n",
    "clin_cols = [c for c in all_cols if c.startswith('clin_') or \n",
    "             c.startswith('clinical_') or c.startswith('disch_')]\n",
    "rad_cols  = [c for c in all_cols if c.startswith('rad_') or \n",
    "             c.startswith('radiology_')]\n",
    "\n",
    "if len(clin_cols) == 0 or len(rad_cols) == 0:\n",
    "    numeric_cols = [c for c in all_cols if np.issubdtype(merged[c].dtype, np.number) \n",
    "                    and c not in temporal_cols and c != 'ventilation_within_12h']\n",
    "    if len(numeric_cols) >= 1500:\n",
    "        clin_cols = numeric_cols[:768]\n",
    "        rad_cols  = numeric_cols[768:1536]\n",
    "\n",
    "temporal_cols = sorted(list(set(temporal_cols)))\n",
    "clin_cols     = sorted(list(set(clin_cols)))\n",
    "rad_cols      = sorted(list(set(rad_cols)))\n",
    "\n",
    "print(f\"Detected counts â†’ temporal: {len(temporal_cols)} | clinical: {len(clin_cols)} | radiology: {len(rad_cols)}\")\n",
    "static_sample = [c for c in merged.columns if c not in temporal_cols + clin_cols + rad_cols][:20]\n",
    "print(\"Sample static cols:\", static_sample)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Coverage checks\n",
    "# ------------------------------------------------------\n",
    "def check_presence(df, cols, name):\n",
    "    if len(cols) == 0:\n",
    "        print(f\"{name}: 0 columns detected.\")\n",
    "        return\n",
    "    frac_present = (df[cols].abs().sum(axis=1) > 0).mean()\n",
    "    print(f\"{name} embeddings present fraction: {frac_present:.3f}\")\n",
    "\n",
    "check_presence(merged, temporal_cols, \"Temporal\")\n",
    "check_presence(merged, clin_cols, \"Clinical\")\n",
    "check_presence(merged, rad_cols,  \"Radiology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:39.939750Z",
     "iopub.status.busy": "2025-11-08T14:01:39.938880Z",
     "iopub.status.idle": "2025-11-08T14:01:42.006070Z",
     "shell.execute_reply": "2025-11-08T14:01:42.005153Z",
     "shell.execute_reply.started": "2025-11-08T14:01:39.939717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric static: ['747_rad', '748_rad', '749_rad', '750_rad', '751_rad', '752_rad', '753_rad', '754_rad', '755_rad', '756_rad', '757_rad', '758_rad', '759_rad', '760_rad', '761_rad', '762_rad', '763_rad', '764_rad', '765_rad', '766_rad']\n",
      "Categorical static: ['gender', 'first_careunit', 'subject_id_temp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39/1753479602.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['has_temporal'] = (df[temporal_cols].abs().sum(axis=1) > 0).astype(int) if len(temporal_cols)>0 else 0\n",
      "/tmp/ipykernel_39/1753479602.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['has_clinical'] = (df[clin_cols].abs().sum(axis=1) > 0).astype(int) if len(clin_cols)>0 else 0\n",
      "/tmp/ipykernel_39/1753479602.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['has_radiology'] = (df[rad_cols].abs().sum(axis=1) > 0).astype(int) if len(rad_cols)>0 else 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes (stays): 5940 736 1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessors to /kaggle/working/fusion_preprocessors.pkl\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Preprocessing & train/val/test splits\n",
    "df = merged.copy()\n",
    "for c in ['subject_id','stay_id']:\n",
    "    if c in df.columns: df[c] = df[c].astype(str)\n",
    "\n",
    "if LABEL_COL not in df.columns:\n",
    "    raise KeyError(f\"Label {LABEL_COL} missing in merged table\")\n",
    "\n",
    "# identify static numeric & categorical columns\n",
    "exclude = set(temporal_cols + clin_cols + rad_cols + ['subject_id','stay_id', LABEL_COL])\n",
    "numeric_static = [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype, np.number)]\n",
    "cat_static = [c for c in df.columns if c not in exclude and not np.issubdtype(df[c].dtype, np.number)]\n",
    "print(\"Numeric static:\", numeric_static[:20])\n",
    "print(\"Categorical static:\", cat_static[:10])\n",
    "\n",
    "# fill embedding NaNs with zeros\n",
    "if len(temporal_cols)>0: df[temporal_cols] = df[temporal_cols].fillna(0.0)\n",
    "if len(clin_cols)>0: df[clin_cols] = df[clin_cols].fillna(0.0)\n",
    "if len(rad_cols)>0: df[rad_cols] = df[rad_cols].fillna(0.0)\n",
    "\n",
    "df['has_temporal'] = (df[temporal_cols].abs().sum(axis=1) > 0).astype(int) if len(temporal_cols)>0 else 0\n",
    "df['has_clinical'] = (df[clin_cols].abs().sum(axis=1) > 0).astype(int) if len(clin_cols)>0 else 0\n",
    "df['has_radiology'] = (df[rad_cols].abs().sum(axis=1) > 0).astype(int) if len(rad_cols)>0 else 0\n",
    "\n",
    "# subject-level split to prevent leakage\n",
    "sub_label = df.groupby('subject_id')[LABEL_COL].max().reset_index().rename(columns={LABEL_COL:'subject_label'})\n",
    "train_sub, test_sub = train_test_split(sub_label, test_size=0.2, random_state=SEED, stratify=sub_label['subject_label'])\n",
    "train_sub, val_sub = train_test_split(train_sub, test_size=0.1111, random_state=SEED, stratify=train_sub['subject_label'])\n",
    "\n",
    "train_df = df[df['subject_id'].isin(train_sub['subject_id'])]\n",
    "val_df   = df[df['subject_id'].isin(val_sub['subject_id'])]\n",
    "test_df  = df[df['subject_id'].isin(test_sub['subject_id'])]\n",
    "print(\"Sizes (stays):\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# standardize numeric statics\n",
    "scaler = StandardScaler()\n",
    "if len(numeric_static)>0:\n",
    "    scaler.fit(train_df[numeric_static].fillna(0.0).values)\n",
    "    X_train_num = scaler.transform(train_df[numeric_static].fillna(0.0).values).astype(np.float32)\n",
    "    X_val_num = scaler.transform(val_df[numeric_static].fillna(0.0).values).astype(np.float32)\n",
    "    X_test_num = scaler.transform(test_df[numeric_static].fillna(0.0).values).astype(np.float32)\n",
    "else:\n",
    "    X_train_num = np.zeros((len(train_df),0),dtype=np.float32)\n",
    "    X_val_num = np.zeros((len(val_df),0),dtype=np.float32)\n",
    "    X_test_num = np.zeros((len(test_df),0),dtype=np.float32)\n",
    "\n",
    "# categorical one-hot\n",
    "if len(cat_static)>0:\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    ohe.fit(train_df[cat_static].fillna(\"NA\"))\n",
    "    X_train_cat = ohe.transform(train_df[cat_static].fillna(\"NA\")).astype(np.float32)\n",
    "    X_val_cat = ohe.transform(val_df[cat_static].fillna(\"NA\")).astype(np.float32)\n",
    "    X_test_cat = ohe.transform(test_df[cat_static].fillna(\"NA\")).astype(np.float32)\n",
    "else:\n",
    "    X_train_cat = np.zeros((len(train_df),0),dtype=np.float32)\n",
    "    X_val_cat = np.zeros((len(val_df),0),dtype=np.float32)\n",
    "    X_test_cat = np.zeros((len(test_df),0),dtype=np.float32)\n",
    "\n",
    "X_train_static = np.hstack([X_train_num, X_train_cat]).astype(np.float32)\n",
    "X_val_static = np.hstack([X_val_num, X_val_cat]).astype(np.float32)\n",
    "X_test_static = np.hstack([X_test_num, X_test_cat]).astype(np.float32)\n",
    "\n",
    "# embeddings arrays\n",
    "X_train_temp = train_df[temporal_cols].values.astype(np.float32) if len(temporal_cols)>0 else np.zeros((len(train_df),0),dtype=np.float32)\n",
    "X_val_temp = val_df[temporal_cols].values.astype(np.float32) if len(temporal_cols)>0 else np.zeros((len(val_df),0),dtype=np.float32)\n",
    "X_test_temp = test_df[temporal_cols].values.astype(np.float32) if len(temporal_cols)>0 else np.zeros((len(test_df),0),dtype=np.float32)\n",
    "\n",
    "X_train_clin = train_df[clin_cols].values.astype(np.float32) if len(clin_cols)>0 else np.zeros((len(train_df),0),dtype=np.float32)\n",
    "X_val_clin = val_df[clin_cols].values.astype(np.float32) if len(clin_cols)>0 else np.zeros((len(val_df),0),dtype=np.float32)\n",
    "X_test_clin = test_df[clin_cols].values.astype(np.float32) if len(clin_cols)>0 else np.zeros((len(test_df),0),dtype=np.float32)\n",
    "\n",
    "X_train_rad = train_df[rad_cols].values.astype(np.float32) if len(rad_cols)>0 else np.zeros((len(train_df),0),dtype=np.float32)\n",
    "X_val_rad = val_df[rad_cols].values.astype(np.float32) if len(rad_cols)>0 else np.zeros((len(val_df),0),dtype=np.float32)\n",
    "X_test_rad = test_df[rad_cols].values.astype(np.float32) if len(rad_cols)>0 else np.zeros((len(test_df),0),dtype=np.float32)\n",
    "\n",
    "y_train = train_df[LABEL_COL].astype(int).values\n",
    "y_val = val_df[LABEL_COL].astype(int).values\n",
    "y_test = test_df[LABEL_COL].astype(int).values\n",
    "\n",
    "# presence masks\n",
    "has_train_temp = train_df['has_temporal'].astype(int).values\n",
    "has_train_clin = train_df['has_clinical'].astype(int).values\n",
    "has_train_rad = train_df['has_radiology'].astype(int).values\n",
    "\n",
    "joblib.dump({'scaler':scaler, 'ohe': (ohe if len(cat_static)>0 else None),\n",
    "             'numeric_static': numeric_static, 'cat_static': cat_static,\n",
    "             'temporal_cols': temporal_cols, 'clin_cols': clin_cols, 'rad_cols': rad_cols},\n",
    "            os.path.join(WORK_DIR,\"fusion_preprocessors.pkl\"))\n",
    "print(\"Saved preprocessors to\", os.path.join(WORK_DIR,\"fusion_preprocessors.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:42.007310Z",
     "iopub.status.busy": "2025-11-08T14:01:42.006988Z",
     "iopub.status.idle": "2025-11-08T14:01:42.035734Z",
     "shell.execute_reply": "2025-11-08T14:01:42.034858Z",
     "shell.execute_reply.started": "2025-11-08T14:01:42.007284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders: 93 12 25\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Dataset and DataLoader with modality dropout\n",
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, X_static, X_temp, X_clin, X_rad, y, has_temp=None, has_clin=None, has_rad=None, modal_dropout_p=0.0):\n",
    "        self.X_static = X_static\n",
    "        self.X_temp = X_temp\n",
    "        self.X_clin = X_clin\n",
    "        self.X_rad = X_rad\n",
    "        self.y = y\n",
    "        self.modal_dropout_p = modal_dropout_p\n",
    "        self.has_temp = has_temp if has_temp is not None else (np.abs(X_temp).sum(axis=1)>0).astype(int)\n",
    "        self.has_clin = has_clin if has_clin is not None else (np.abs(X_clin).sum(axis=1)>0).astype(int)\n",
    "        self.has_rad  = has_rad  if has_rad  is not None else (np.abs(X_rad).sum(axis=1)>0).astype(int)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.X_static[idx] if self.X_static.shape[1]>0 else np.zeros((0,),dtype=np.float32)\n",
    "        t = self.X_temp[idx] if self.X_temp.shape[1]>0 else np.zeros((0,),dtype=np.float32)\n",
    "        c = self.X_clin[idx] if self.X_clin.shape[1]>0 else np.zeros((0,),dtype=np.float32)\n",
    "        r = self.X_rad[idx] if self.X_rad.shape[1]>0 else np.zeros((0,),dtype=np.float32)\n",
    "        has_t,has_c,has_r = int(self.has_temp[idx]), int(self.has_clin[idx]), int(self.has_rad[idx])\n",
    "        # modality dropout: randomly zero-out present modalities\n",
    "        if self.modal_dropout_p>0:\n",
    "            if has_t and random.random() < self.modal_dropout_p: t = np.zeros_like(t)\n",
    "            if has_c and random.random() < self.modal_dropout_p: c = np.zeros_like(c)\n",
    "            if has_r and random.random() < self.modal_dropout_p: r = np.zeros_like(r)\n",
    "        return {\n",
    "            'static': torch.from_numpy(s).float(),\n",
    "            'temp': torch.from_numpy(t).float(),\n",
    "            'clin': torch.from_numpy(c).float(),\n",
    "            'rad': torch.from_numpy(r).float(),\n",
    "            'has_temp': torch.tensor(has_t, dtype=torch.float32),\n",
    "            'has_clin': torch.tensor(has_c, dtype=torch.float32),\n",
    "            'has_rad': torch.tensor(has_r, dtype=torch.float32),\n",
    "            'label': torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_ds = FusionDataset(X_train_static, X_train_temp, X_train_clin, X_train_rad, y_train,\n",
    "                         has_temp=has_train_temp, has_clin=has_train_clin, has_rad=has_train_rad, modal_dropout_p=0.15)\n",
    "val_ds = FusionDataset(X_val_static, X_val_temp, X_val_clin, X_val_rad, y_val, modal_dropout_p=0.0)\n",
    "test_ds = FusionDataset(X_test_static, X_test_temp, X_test_clin, X_test_rad, y_test, modal_dropout_p=0.0)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Loaders:\", len(train_loader), len(val_loader), len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:42.037070Z",
     "iopub.status.busy": "2025-11-08T14:01:42.036817Z",
     "iopub.status.idle": "2025-11-08T14:01:42.049209Z",
     "shell.execute_reply": "2025-11-08T14:01:42.048176Z",
     "shell.execute_reply.started": "2025-11-08T14:01:42.037048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CELL 4: Model definition\n",
    "class GatedFusionModel(nn.Module):\n",
    "    def __init__(self, static_dim, temp_dim, clin_dim, rad_dim, proj_dim=128, hidden=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.proj_dim = proj_dim\n",
    "        # projections (if a modality has 0 dim, set projection to None)\n",
    "        self.static_proj = nn.Sequential(nn.Linear(static_dim, proj_dim), nn.ReLU()) if static_dim>0 else None\n",
    "        self.temp_proj = nn.Sequential(nn.Linear(temp_dim, proj_dim), nn.ReLU()) if temp_dim>0 else None\n",
    "        self.clin_proj = nn.Sequential(nn.Linear(clin_dim, proj_dim), nn.ReLU()) if clin_dim>0 else None\n",
    "        self.rad_proj  = nn.Sequential(nn.Linear(rad_dim, proj_dim), nn.ReLU()) if rad_dim>0 else None\n",
    "\n",
    "        # gating logits for each modality (map proj_dim -> scalar)\n",
    "        self.gate_static = nn.Sequential(nn.Linear(proj_dim, proj_dim//2), nn.ReLU(), nn.Linear(proj_dim//2,1)) if self.static_proj is not None else None\n",
    "        self.gate_temp = nn.Sequential(nn.Linear(proj_dim, proj_dim//2), nn.ReLU(), nn.Linear(proj_dim//2,1)) if self.temp_proj is not None else None\n",
    "        self.gate_clin = nn.Sequential(nn.Linear(proj_dim, proj_dim//2), nn.ReLU(), nn.Linear(proj_dim//2,1)) if self.clin_proj is not None else None\n",
    "        self.gate_rad = nn.Sequential(nn.Linear(proj_dim, proj_dim//2), nn.ReLU(), nn.Linear(proj_dim//2,1)) if self.rad_proj is not None else None\n",
    "\n",
    "        # final classifier: take gated fused vector\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(proj_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_x, temp_x, clin_x, rad_x):\n",
    "        mods = []\n",
    "        gate_logits = []\n",
    "        # project\n",
    "        if self.static_proj is not None:\n",
    "            s = self.static_proj(static_x)\n",
    "            mods.append(s); gate_logits.append(self.gate_static(s))\n",
    "        if self.temp_proj is not None:\n",
    "            t = self.temp_proj(temp_x)\n",
    "            mods.append(t); gate_logits.append(self.gate_temp(t))\n",
    "        if self.clin_proj is not None:\n",
    "            c = self.clin_proj(clin_x)\n",
    "            mods.append(c); gate_logits.append(self.gate_clin(c))\n",
    "        if self.rad_proj is not None:\n",
    "            r = self.rad_proj(rad_x)\n",
    "            mods.append(r); gate_logits.append(self.gate_rad(r))\n",
    "        if len(mods)==0:\n",
    "            raise ValueError(\"No modalities provided to model!\")\n",
    "\n",
    "        # gate logits shape: list of (B,1) -> cat -> (B, M)\n",
    "        gate_tensor = torch.cat(gate_logits, dim=1)  # (B, M)\n",
    "        gates = torch.softmax(gate_tensor, dim=1)   # (B, M)\n",
    "\n",
    "        # weighted sum of modality vectors: for each mod i, multiply mods[i] * gates[:,i:i+1]\n",
    "        fused = torch.zeros_like(mods[0])\n",
    "        for i,m in enumerate(mods):\n",
    "            w = gates[:, i:i+1]\n",
    "            fused = fused + m * w\n",
    "        logits = self.classifier(fused).squeeze(1)\n",
    "        return logits, gates  # gates for interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:42.052462Z",
     "iopub.status.busy": "2025-11-08T14:01:42.051820Z",
     "iopub.status.idle": "2025-11-08T14:01:58.566077Z",
     "shell.execute_reply": "2025-11-08T14:01:58.565183Z",
     "shell.execute_reply.started": "2025-11-08T14:01:42.052427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims static,temp,clin,rad: 4369 128 768 768\n",
      "GatedFusionModel(\n",
      "  (static_proj): Sequential(\n",
      "    (0): Linear(in_features=4369, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (temp_proj): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (clin_proj): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (rad_proj): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (gate_static): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (gate_temp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (gate_clin): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (gate_rad): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 loss=11106.9286 val_auprc=0.7428 val_auroc=0.8885\n",
      "âœ… Saved best ckpt: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "Epoch 2/40 loss=0.8834 val_auprc=0.7483 val_auroc=0.8975\n",
      "âœ… Saved best ckpt: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "Epoch 3/40 loss=0.8463 val_auprc=0.7467 val_auroc=0.8977\n",
      "Epoch 4/40 loss=0.8431 val_auprc=0.7487 val_auroc=0.8970\n",
      "âœ… Saved best ckpt: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "Epoch 5/40 loss=0.8414 val_auprc=0.7513 val_auroc=0.8979\n",
      "âœ… Saved best ckpt: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "Epoch 6/40 loss=0.8322 val_auprc=0.7521 val_auroc=0.8956\n",
      "âœ… Saved best ckpt: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "Epoch 7/40 loss=0.8247 val_auprc=0.7451 val_auroc=0.8943\n",
      "Epoch 8/40 loss=0.8179 val_auprc=0.7463 val_auroc=0.8919\n",
      "Epoch 9/40 loss=0.8003 val_auprc=0.7381 val_auroc=0.8892\n",
      "Epoch 10/40 loss=0.8044 val_auprc=0.7372 val_auroc=0.8861\n",
      "Epoch 11/40 loss=0.8055 val_auprc=0.7365 val_auroc=0.8849\n",
      "Epoch 12/40 loss=0.7790 val_auprc=0.7367 val_auroc=0.8839\n",
      "â¹ï¸ Early stopping: no improvement for 6 epochs\n",
      "Training complete. Best val AUPRC: 0.7520953507808116\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# CELL 5: Training loop (with balanced gate regularization)\n",
    "# ======================================================\n",
    "\n",
    "static_dim = X_train_static.shape[1]\n",
    "temp_dim   = X_train_temp.shape[1]\n",
    "clin_dim   = X_train_clin.shape[1]\n",
    "rad_dim    = X_train_rad.shape[1]\n",
    "print(\"Dims static,temp,clin,rad:\", static_dim, temp_dim, clin_dim, rad_dim)\n",
    "\n",
    "model = GatedFusionModel(static_dim, temp_dim, clin_dim, rad_dim,\n",
    "                         proj_dim=128, hidden=128, dropout=0.2).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Loss + optimizer setup\n",
    "# ------------------------------------------------------\n",
    "pos = y_train.sum(); neg = (len(y_train)-pos)\n",
    "pos_weight = torch.tensor([(neg / (pos + 1e-9))]).to(DEVICE)\n",
    "bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Gate regularizer hyperparameters\n",
    "# ------------------------------------------------------\n",
    "LAMBDA_GATE_UNIFORM = 0.5    # push gates to share weight among present modalities\n",
    "LAMBDA_GATE_BIAS    = 0.001  # small bias toward equal weighting (â‰ˆ0.25 each)\n",
    "MAX_EPOCHS = 40\n",
    "best_val_ap = -1.0\n",
    "best_ckpt = os.path.join(WORK_DIR, \"best_fusion_retrain_ckpt.pth\")\n",
    "patience = 6\n",
    "no_improve = 0\n",
    "\n",
    "\n",
    "def compute_gate_reg(gates, has_mask):\n",
    "    \"\"\"\n",
    "    Encourage gates to distribute weights evenly among *present* modalities.\n",
    "    \"\"\"\n",
    "    s = has_mask.sum(dim=1, keepdim=True).clamp(min=1.0)\n",
    "    uniform = has_mask / s  # desired uniform weights among present modalities\n",
    "    reg = ((gates - uniform) * has_mask).pow(2).sum(dim=1) / (s.squeeze() + 1e-9)\n",
    "    return reg.mean()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Training loop\n",
    "# ------------------------------------------------------\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        s = batch[\"static\"].to(DEVICE)\n",
    "        t = batch[\"temp\"].to(DEVICE)\n",
    "        c = batch[\"clin\"].to(DEVICE)\n",
    "        r = batch[\"rad\"].to(DEVICE)\n",
    "        label = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "        has_temp = batch[\"has_temp\"].to(DEVICE)\n",
    "        has_clin = batch[\"has_clin\"].to(DEVICE)\n",
    "        has_rad  = batch[\"has_rad\"].to(DEVICE)\n",
    "\n",
    "        # Stack presence mask (static always assumed present)\n",
    "        has_mask = []\n",
    "        if model.static_proj is not None:\n",
    "            has_mask.append(torch.ones_like(has_temp))\n",
    "        if model.temp_proj is not None:\n",
    "            has_mask.append(has_temp)\n",
    "        if model.clin_proj is not None:\n",
    "            has_mask.append(has_clin)\n",
    "        if model.rad_proj is not None:\n",
    "            has_mask.append(has_rad)\n",
    "        has_mask = torch.stack(has_mask, dim=1).float()  # (B, M)\n",
    "\n",
    "        # Forward\n",
    "        logits, gates = model(s, t, c, r)\n",
    "        loss_main = bce_loss(logits, label)\n",
    "\n",
    "        # --- Gate regularization ---\n",
    "        reg_uniform = compute_gate_reg(gates, has_mask)  # encourage balanced use of present modalities\n",
    "        reg_bias = torch.mean((gates - 0.25) ** 2)       # gentle bias toward equal gates overall\n",
    "        loss = loss_main + LAMBDA_GATE_UNIFORM * reg_uniform + LAMBDA_GATE_BIAS * reg_bias\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Validation\n",
    "    # ------------------------------------------------------\n",
    "    model.eval()\n",
    "    val_probs, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            s = batch[\"static\"].to(DEVICE)\n",
    "            t = batch[\"temp\"].to(DEVICE)\n",
    "            c = batch[\"clin\"].to(DEVICE)\n",
    "            r = batch[\"rad\"].to(DEVICE)\n",
    "            label = batch[\"label\"].cpu().numpy()\n",
    "\n",
    "            logits, _ = model(s, t, c, r)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            val_probs.append(probs)\n",
    "            val_labels.append(label)\n",
    "\n",
    "    val_probs = np.concatenate(val_probs)\n",
    "    val_labels = np.concatenate(val_labels)\n",
    "    val_auprc = average_precision_score(val_labels, val_probs)\n",
    "    val_auroc = roc_auc_score(val_labels, val_probs)\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{MAX_EPOCHS} \"\n",
    "          f\"loss={avg_loss:.4f} val_auprc={val_auprc:.4f} val_auroc={val_auroc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_auprc)\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if val_auprc > best_val_ap:\n",
    "        best_val_ap = val_auprc\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_probs\": val_probs,\n",
    "            \"val_labels\": val_labels,\n",
    "            \"scaler_ohe\": os.path.join(WORK_DIR, \"fusion_preprocessors.pkl\")\n",
    "        }, best_ckpt)\n",
    "        print(\"âœ… Saved best ckpt:\", best_ckpt)\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    if no_improve >= patience:\n",
    "        print(f\"â¹ï¸ Early stopping: no improvement for {patience} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete. Best val AUPRC:\", best_val_ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:58.567719Z",
     "iopub.status.busy": "2025-11-08T14:01:58.567060Z",
     "iopub.status.idle": "2025-11-08T14:01:58.820241Z",
     "shell.execute_reply": "2025-11-08T14:01:58.819361Z",
     "shell.execute_reply.started": "2025-11-08T14:01:58.567692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.8648694274751351\n",
      "Test AUPRC: 0.7226107123542618\n",
      "Test F1 (0.5): 0.6774193548387096\n",
      "Test Brier: 0.09976624991254829\n",
      "Calibrated test AUPRC: 0.6855510717515387\n",
      "Saved test outputs to /kaggle/working/fusion_test_outputs_retrained.csv\n",
      "Saved final ckpt\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: load best ckpt and evaluate on test set, isotonic calibration\n",
    "ck = torch.load(best_ckpt, map_location=DEVICE, weights_only=False)\n",
    "model.load_state_dict(ck['model_state_dict'])\n",
    "model.eval()\n",
    "# compute test probs\n",
    "test_probs = []\n",
    "test_labels = []\n",
    "gates_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        s = batch['static'].to(DEVICE); t = batch['temp'].to(DEVICE); c = batch['clin'].to(DEVICE); r = batch['rad'].to(DEVICE)\n",
    "        labels = batch['label'].cpu().numpy()\n",
    "        logits, gates = model(s,t,c,r)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        test_probs.append(probs); test_labels.append(labels); gates_list.append(gates.cpu().numpy())\n",
    "test_probs = np.concatenate(test_probs)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "gates_arr = np.vstack(gates_list)\n",
    "print(\"Test AUROC:\", roc_auc_score(test_labels, test_probs))\n",
    "print(\"Test AUPRC:\", average_precision_score(test_labels, test_probs))\n",
    "print(\"Test F1 (0.5):\", f1_score(test_labels, (test_probs>=0.5).astype(int)))\n",
    "print(\"Test Brier:\", brier_score_loss(test_labels, test_probs))\n",
    "\n",
    "# isotonic calibration on val set (saved in ckpt)\n",
    "val_probs = ck.get('val_probs')\n",
    "val_labels = ck.get('val_labels')\n",
    "if val_probs is not None and val_labels is not None:\n",
    "    iso = IsotonicRegression(out_of_bounds='clip')\n",
    "    iso.fit(val_probs, val_labels)\n",
    "    test_probs_cal = iso.transform(test_probs)\n",
    "    print(\"Calibrated test AUPRC:\", average_precision_score(test_labels, test_probs_cal))\n",
    "    # save calibrated test probs & labels\n",
    "    np.save(os.path.join(WORK_DIR, \"test_probs_calibrated.npy\"), test_probs_cal)\n",
    "else:\n",
    "    test_probs_cal = test_probs\n",
    "    print(\"No val probs saved in ckpt; skipping isotonic.\")\n",
    "\n",
    "# save inference outputs (with gates) aligned to test_df\n",
    "out_df = test_df.reset_index(drop=True)[['subject_id','stay_id']].copy()\n",
    "out_df['raw_prob'] = test_probs\n",
    "out_df['calibrated_prob'] = test_probs_cal\n",
    "out_df['pred_label'] = (out_df['calibrated_prob'] >= 0.5).astype(int)\n",
    "# gates order: match model gating order: static,temp,clin,rad where present\n",
    "modal_names = []\n",
    "if model.static_proj is not None: modal_names.append('static')\n",
    "if model.temp_proj is not None: modal_names.append('temp')\n",
    "if model.clin_proj is not None: modal_names.append('clin')\n",
    "if model.rad_proj is not None: modal_names.append('rad')\n",
    "for i,name in enumerate(modal_names):\n",
    "    out_df[f'gate_{name}'] = gates_arr[:, i]\n",
    "out_df.to_csv(os.path.join(WORK_DIR, \"fusion_test_outputs_retrained.csv\"), index=False)\n",
    "print(\"Saved test outputs to\", os.path.join(WORK_DIR, \"fusion_test_outputs_retrained.csv\"))\n",
    "# save checkpoint (redundant)\n",
    "torch.save({'model_state_dict': model.state_dict(), 'preproc': os.path.join(WORK_DIR,\"fusion_preprocessors.pkl\")}, os.path.join(WORK_DIR, \"final_fusion_retrained_ckpt.pth\"))\n",
    "print(\"Saved final ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:01:59.925098Z",
     "iopub.status.busy": "2025-11-08T14:01:59.924884Z",
     "iopub.status.idle": "2025-11-08T14:02:10.030219Z",
     "shell.execute_reply": "2025-11-08T14:02:10.029468Z",
     "shell.execute_reply.started": "2025-11-08T14:01:59.925082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint: /kaggle/working/best_fusion_retrain_ckpt.pth\n",
      "âœ… Loaded model. Starting fine-tune...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fine-tune] Epoch 1/10 loss=0.8184 val_auprc=0.7513 val_auroc=0.8956\n",
      "[Fine-tune] Epoch 2/10 loss=0.8125 val_auprc=0.7513 val_auroc=0.8951\n",
      "[Fine-tune] Epoch 3/10 loss=0.8204 val_auprc=0.7487 val_auroc=0.8942\n",
      "[Fine-tune] Epoch 4/10 loss=0.8011 val_auprc=0.7469 val_auroc=0.8935\n",
      "[Fine-tune] Epoch 5/10 loss=0.8071 val_auprc=0.7475 val_auroc=0.8934\n",
      "[Fine-tune] Epoch 6/10 loss=0.8048 val_auprc=0.7465 val_auroc=0.8927\n",
      "[Fine-tune] Epoch 7/10 loss=0.7860 val_auprc=0.7466 val_auroc=0.8927\n",
      "[Fine-tune] Epoch 8/10 loss=0.7996 val_auprc=0.7459 val_auroc=0.8924\n",
      "[Fine-tune] Epoch 9/10 loss=0.7960 val_auprc=0.7462 val_auroc=0.8923\n",
      "[Fine-tune] Epoch 10/10 loss=0.8001 val_auprc=0.7449 val_auroc=0.8917\n",
      "âœ… Fine-tuned model saved to: /kaggle/working/fusion_finetuned_ckpt.pth\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# CELL 6: Fine-tuning from saved checkpoint with rebalanced gates\n",
    "# ======================================================\n",
    "\n",
    "# Adjusted regularization weights\n",
    "LAMBDA_GATE_UNIFORM = 0.3\n",
    "LAMBDA_GATE_BIAS = 0.005\n",
    "FINE_TUNE_EPOCHS = 10  # short fine-tune run\n",
    "\n",
    "print(f\"Resuming from checkpoint: {best_ckpt}\")\n",
    "ckpt = torch.load(best_ckpt, map_location=DEVICE, weights_only=False)\n",
    "\n",
    "model = GatedFusionModel(static_dim, temp_dim, clin_dim, rad_dim,\n",
    "                         proj_dim=128, hidden=128, dropout=0.2).to(DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=2, verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Loaded model. Starting fine-tune...\")\n",
    "\n",
    "def compute_gate_reg(gates, has_mask):\n",
    "    s = has_mask.sum(dim=1, keepdim=True).clamp(min=1.0)\n",
    "    uniform = has_mask / s\n",
    "    reg = ((gates - uniform) * has_mask).pow(2).sum(dim=1) / (s.squeeze() + 1e-9)\n",
    "    return reg.mean()\n",
    "\n",
    "for epoch in range(1, FINE_TUNE_EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        s = batch[\"static\"].to(DEVICE)\n",
    "        t = batch[\"temp\"].to(DEVICE)\n",
    "        c = batch[\"clin\"].to(DEVICE)\n",
    "        r = batch[\"rad\"].to(DEVICE)\n",
    "        label = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "        has_temp = batch[\"has_temp\"].to(DEVICE)\n",
    "        has_clin = batch[\"has_clin\"].to(DEVICE)\n",
    "        has_rad  = batch[\"has_rad\"].to(DEVICE)\n",
    "        has_mask = torch.stack([\n",
    "            torch.ones_like(has_temp), has_temp, has_clin, has_rad\n",
    "        ], dim=1).float()\n",
    "\n",
    "        logits, gates = model(s, t, c, r)\n",
    "        loss_main = bce_loss(logits, label)\n",
    "        reg_uniform = compute_gate_reg(gates, has_mask)\n",
    "        reg_bias = torch.mean((gates - torch.tensor([0.2, 0.4, 0.2, 0.2], device=gates.device)) ** 2)\n",
    "        loss = loss_main + LAMBDA_GATE_UNIFORM * reg_uniform + LAMBDA_GATE_BIAS * reg_bias\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_probs, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            s = batch[\"static\"].to(DEVICE)\n",
    "            t = batch[\"temp\"].to(DEVICE)\n",
    "            c = batch[\"clin\"].to(DEVICE)\n",
    "            r = batch[\"rad\"].to(DEVICE)\n",
    "            label = batch[\"label\"].cpu().numpy()\n",
    "\n",
    "            logits, _ = model(s, t, c, r)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            val_probs.append(probs)\n",
    "            val_labels.append(label)\n",
    "\n",
    "    val_probs = np.concatenate(val_probs)\n",
    "    val_labels = np.concatenate(val_labels)\n",
    "    val_auprc = average_precision_score(val_labels, val_probs)\n",
    "    val_auroc = roc_auc_score(val_labels, val_probs)\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "\n",
    "    print(f\"[Fine-tune] Epoch {epoch}/{FINE_TUNE_EPOCHS} \"\n",
    "          f\"loss={avg_loss:.4f} val_auprc={val_auprc:.4f} val_auroc={val_auroc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_auprc)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "fine_ckpt = os.path.join(WORK_DIR, \"fusion_finetuned_ckpt.pth\")\n",
    "torch.save(model.state_dict(), fine_ckpt)\n",
    "print(f\"âœ… Fine-tuned model saved to: {fine_ckpt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:07:46.176206Z",
     "iopub.status.busy": "2025-11-08T14:07:46.175888Z",
     "iopub.status.idle": "2025-11-08T14:08:00.169938Z",
     "shell.execute_reply": "2025-11-08T14:08:00.169153Z",
     "shell.execute_reply.started": "2025-11-08T14:07:46.176184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background shape: torch.Size([30, 6033]) Explain shape: (30, 6033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 14:07:48.098287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762610868.317356      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762610868.385914      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepExplainer failed: <class 'function'> is not currently a supported model type!\n",
      "GradientExplainer also failed: <class 'function'> is not currently a supported model type!\n",
      "No gradient-based SHAP produced.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_39/2266462087.py\", line 69, in <cell line: 0>\n",
      "    explainer = shap.DeepExplainer(model_forward_torch, background)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/__init__.py\", line 84, in __init__\n",
      "    self.explainer = TFDeep(model, data, session, learning_phase_flags)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 103, in __init__\n",
      "    self.model_inputs = _get_model_inputs(model)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/tf_utils.py\", line 71, in _get_model_inputs\n",
      "    raise ValueError(emsg)\n",
      "ValueError: <class 'function'> is not currently a supported model type!\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_39/2266462087.py\", line 69, in <cell line: 0>\n",
      "    explainer = shap.DeepExplainer(model_forward_torch, background)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/__init__.py\", line 84, in __init__\n",
      "    self.explainer = TFDeep(model, data, session, learning_phase_flags)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 103, in __init__\n",
      "    self.model_inputs = _get_model_inputs(model)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/tf_utils.py\", line 71, in _get_model_inputs\n",
      "    raise ValueError(emsg)\n",
      "ValueError: <class 'function'> is not currently a supported model type!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_39/2266462087.py\", line 81, in <cell line: 0>\n",
      "    explainer = shap.GradientExplainer(model_fn_for_grad, X_train_concat[bg_idx])\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_gradient.py\", line 83, in __init__\n",
      "    self.explainer = _TFGradient(model, data, session, batch_size, local_smoothing)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_gradient.py\", line 167, in __init__\n",
      "    self.model_inputs = _get_model_inputs(model)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/tf_utils.py\", line 71, in _get_model_inputs\n",
      "    raise ValueError(emsg)\n",
      "ValueError: <class 'function'> is not currently a supported model type!\n"
     ]
    }
   ],
   "source": [
    "# CELL: SHAP Gradient/Deep Explainer (preferred, faster & stable for PyTorch)\n",
    "import shap, joblib, time, gc, traceback, numpy as np\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Make sure model is on DEVICE and eval()\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Build concatenated arrays if not present\n",
    "X_train_concat = np.concatenate([X_train_static, X_train_temp, X_train_clin, X_train_rad], axis=1)\n",
    "X_test_concat  = np.concatenate([X_test_static, X_test_temp, X_test_clin, X_test_rad], axis=1)\n",
    "\n",
    "# dims\n",
    "s_dim = X_train_static.shape[1]\n",
    "t_dim = X_train_temp.shape[1]\n",
    "c_dim = X_train_clin.shape[1]\n",
    "r_dim = X_train_rad.shape[1]\n",
    "\n",
    "# Helper to convert concatenated numpy -> model prob tensor\n",
    "def predict_from_concat_array(x_np):\n",
    "    # x_np shape (B, D)\n",
    "    B = x_np.shape[0]\n",
    "    s = x_np[:, :s_dim].reshape(B, s_dim)\n",
    "    t = x_np[:, s_dim:s_dim+t_dim].reshape(B, t_dim)\n",
    "    c = x_np[:, s_dim+t_dim:s_dim+t_dim+c_dim].reshape(B, c_dim)\n",
    "    r = x_np[:, s_dim+t_dim+c_dim:].reshape(B, r_dim)\n",
    "    with torch.no_grad():\n",
    "        s_t = torch.tensor(s, dtype=torch.float32).to(DEVICE)\n",
    "        t_t = torch.tensor(t, dtype=torch.float32).to(DEVICE)\n",
    "        c_t = torch.tensor(c, dtype=torch.float32).to(DEVICE)\n",
    "        r_t = torch.tensor(r, dtype=torch.float32).to(DEVICE)\n",
    "        logits, _ = model(s_t, t_t, c_t, r_t)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "# Create a small background (use train samples)\n",
    "bg_size = min(30, X_train_concat.shape[0])\n",
    "rng = np.random.RandomState(SEED if 'SEED' in globals() else 42)\n",
    "bg_idx = rng.choice(X_train_concat.shape[0], bg_size, replace=False)\n",
    "background = torch.tensor(X_train_concat[bg_idx], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# Choose explain samples (small)\n",
    "sample_size = min(30, X_test_concat.shape[0])\n",
    "sample_idx = rng.choice(X_test_concat.shape[0], sample_size, replace=False)\n",
    "X_explain = X_test_concat[sample_idx]\n",
    "\n",
    "print(\"Background shape:\", background.shape, \"Explain shape:\", X_explain.shape)\n",
    "\n",
    "# Try DeepExplainer first (works with some PyTorch models), otherwise GradientExplainer\n",
    "shap_values = None\n",
    "start = time.time()\n",
    "try:\n",
    "    # DeepExplainer expects model outputs as torch tensors; wrapper returns logits/probs\n",
    "    def model_forward_torch(x_t):\n",
    "        # x_t is torch tensor of shape (B, D_concat)\n",
    "        B = x_t.shape[0]\n",
    "        s = x_t[:, :s_dim]\n",
    "        t = x_t[:, s_dim:s_dim+t_dim]\n",
    "        c = x_t[:, s_dim+t_dim:s_dim+t_dim+c_dim]\n",
    "        r = x_t[:, s_dim+t_dim+c_dim:]\n",
    "        logits, _ = model(s, t, c, r)\n",
    "        probs = torch.sigmoid(logits).unsqueeze(1)  # (B,1)\n",
    "        return probs\n",
    "\n",
    "    # Use DeepExplainer with background as torch tensor\n",
    "    explainer = shap.DeepExplainer(model_forward_torch, background)\n",
    "    shap_values = explainer.shap_values(torch.tensor(X_explain, dtype=torch.float32).to(DEVICE))\n",
    "    print(\"Used DeepExplainer. Time:\", time.time()-start)\n",
    "except Exception as e_de:\n",
    "    print(\"DeepExplainer failed:\", e_de)\n",
    "    traceback.print_exc()\n",
    "    try:\n",
    "        # fallback to GradientExplainer which uses model gradients\n",
    "        start2 = time.time()\n",
    "        # Note: GradientExplainer can accept a model function returning tensor(s) and background as numpy/torch\n",
    "        def model_fn_for_grad(x):\n",
    "            return torch.tensor(predict_from_concat_array(np.array(x)), dtype=np.float32)\n",
    "        explainer = shap.GradientExplainer(model_fn_for_grad, X_train_concat[bg_idx])\n",
    "        shap_values = explainer.shap_values(X_explain)\n",
    "        print(\"Used GradientExplainer. Time:\", time.time()-start2)\n",
    "    except Exception as e_grad:\n",
    "        print(\"GradientExplainer also failed:\", e_grad)\n",
    "        traceback.print_exc()\n",
    "        shap_values = None\n",
    "\n",
    "# Save & plot results if we have shap_values\n",
    "if shap_values is not None:\n",
    "    shap_vals_arr = np.array(shap_values)\n",
    "    outpath = os.path.join(EXPLAIN_DIR, f\"shap_gradient_{WINDOW}.pkl\")\n",
    "    joblib.dump({'shap_vals': shap_vals_arr, 'X_explain': X_explain, 'sample_idx': sample_idx}, outpath)\n",
    "    print(\"Saved SHAP to:\", outpath)\n",
    "    # mean abs importance\n",
    "    mean_abs = np.mean(np.abs(shap_vals_arr), axis=0)\n",
    "    topk = min(30, mean_abs.shape[-1])\n",
    "    idx_sort = np.argsort(-mean_abs)[0][:topk] if mean_abs.ndim==2 else np.argsort(-mean_abs)[:topk]\n",
    "    feat_names = []\n",
    "    if len(numeric_static)>0: feat_names += numeric_static\n",
    "    if 'X_train_cat' in globals() and X_train_cat.shape[1]>0: feat_names += [f\"cat_{i}\" for i in range(X_train_cat.shape[1])]\n",
    "    feat_names += [f\"temp_{i}\" for i in range(X_train_temp.shape[1])]\n",
    "    feat_names += [f\"clin_{i}\" for i in range(X_train_clin.shape[1])]\n",
    "    feat_names += [f\"rad_{i}\" for i in range(X_train_rad.shape[1])]\n",
    "    if len(feat_names) != mean_abs.shape[-1]:\n",
    "        feat_names = [f\"feat_{i}\" for i in range(mean_abs.shape[-1])]\n",
    "    # Flatten mean_abs if needed\n",
    "    mabs = mean_abs if mean_abs.ndim==1 else mean_abs.mean(axis=0)\n",
    "    idx_sort = np.argsort(-mabs)[:topk]\n",
    "    plt.figure(figsize=(8, max(4, topk*0.22)))\n",
    "    plt.barh([feat_names[i] for i in idx_sort[::-1]], mabs[idx_sort][::-1])\n",
    "    plt.title(\"Top mean |SHAP| (gradient-based)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(EXPLAIN_DIR, f\"shap_gradient_top{topk}_{WINDOW}.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved SHAP top plot.\")\n",
    "else:\n",
    "    print(\"No gradient-based SHAP produced.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:11:22.898275Z",
     "iopub.status.busy": "2025-11-08T14:11:22.897498Z",
     "iopub.status.idle": "2025-11-08T14:11:53.101784Z",
     "shell.execute_reply": "2025-11-08T14:11:53.100941Z",
     "shell.execute_reply.started": "2025-11-08T14:11:22.898249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig dims: 6033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6467c81fe944db28f19a570d150356c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-SHAP done shape: (50, 50)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA+SHAP artifacts.\n"
     ]
    }
   ],
   "source": [
    "# === PCA + Kernel SHAP fallback ===\n",
    "import numpy as np, joblib, time, gc\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "\n",
    "gc.collect()\n",
    "X_train_concat = np.concatenate([X_train_static, X_train_temp, X_train_clin, X_train_rad], axis=1)\n",
    "X_test_concat  = np.concatenate([X_test_static, X_test_temp, X_test_clin, X_test_rad], axis=1)\n",
    "print(\"Orig dims:\", X_train_concat.shape[1])\n",
    "\n",
    "k = 50  # target PCA dims (adjust)\n",
    "pca = PCA(n_components=k, random_state=SEED)\n",
    "pca.fit(X_train_concat)\n",
    "X_train_pca = pca.transform(X_train_concat)\n",
    "X_test_pca  = pca.transform(X_test_concat)\n",
    "\n",
    "# wrapper predict fn for PCA inputs\n",
    "def predict_pca(x_pca):\n",
    "    # x_pca: numpy (B,k) -> reconstruct to orig dims (approx) and predict\n",
    "    X_approx = pca.inverse_transform(x_pca)\n",
    "    return model_predict_np(X_approx)  # reuses earlier model_predict_np wrapper (must exist)\n",
    "\n",
    "# KernelExplainer on PCA space (smaller)\n",
    "bg_size = min(50, X_train_pca.shape[0])\n",
    "sample_size = min(50, X_test_pca.shape[0])\n",
    "rng = np.random.RandomState(SEED)\n",
    "bg_idx = rng.choice(X_train_pca.shape[0], bg_size, replace=False)\n",
    "sample_idx = rng.choice(X_test_pca.shape[0], sample_size, replace=False)\n",
    "bg = X_train_pca[bg_idx]\n",
    "X_explain_pca = X_test_pca[sample_idx]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_pca, bg)\n",
    "shap_vals_pca = explainer.shap_values(X_explain_pca, nsamples=200)  # adjust nsamples as needed\n",
    "shap_vals_pca = np.array(shap_vals_pca)\n",
    "print(\"PCA-SHAP done shape:\", shap_vals_pca.shape)\n",
    "\n",
    "# Map PCA feature importances back to original dimensions by multiplying PCA components\n",
    "# mean_abs in PCA space\n",
    "mean_abs_pca = np.mean(np.abs(shap_vals_pca), axis=0)\n",
    "# importance per original feature approx = sum_j |mean_abs_pca_j * |pca.components_[j, i]||\n",
    "orig_imp = np.sum(np.abs(mean_abs_pca[:, None] * pca.components_), axis=0)\n",
    "# get top original features\n",
    "idx_top = np.argsort(-orig_imp)[:30]\n",
    "feat_names_full = []\n",
    "if len(numeric_static)>0: feat_names_full += numeric_static\n",
    "if 'X_train_cat' in globals() and X_train_cat.shape[1]>0: feat_names_full += [f\"cat_{i}\" for i in range(X_train_cat.shape[1])]\n",
    "feat_names_full += [f\"temp_{i}\" for i in range(X_train_temp.shape[1])]\n",
    "feat_names_full += [f\"clin_{i}\" for i in range(X_train_clin.shape[1])]\n",
    "feat_names_full += [f\"rad_{i}\" for i in range(X_train_rad.shape[1])]\n",
    "if len(feat_names_full) != orig_imp.shape[0]:\n",
    "    feat_names_full = [f\"feat_{i}\" for i in range(orig_imp.shape[0])]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.barh([feat_names_full[i] for i in idx_top[::-1]], orig_imp[idx_top][::-1])\n",
    "plt.title(\"PCA+KernelSHAP approx top features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPLAIN_DIR, f\"pca_shap_top30_{WINDOW}.png\"), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save outputs\n",
    "joblib.dump({'pca': pca, 'shap_vals_pca': shap_vals_pca, 'orig_imp': orig_imp, 'feat_names_full': feat_names_full}, os.path.join(EXPLAIN_DIR, f\"pca_shap_{WINDOW}.pkl\"))\n",
    "print(\"Saved PCA+SHAP artifacts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:16:10.178722Z",
     "iopub.status.busy": "2025-11-08T14:16:10.178008Z",
     "iopub.status.idle": "2025-11-08T14:17:22.508548Z",
     "shell.execute_reply": "2025-11-08T14:17:22.507316Z",
     "shell.execute_reply.started": "2025-11-08T14:16:10.178696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captum not found â€” installing captum...\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/3849916680.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcaptum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcaptum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntegratedGradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'captum'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/3849916680.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install captum --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcaptum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntegratedGradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"spec not found for the module {name!r}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_TritonLibrary\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623"
     ]
    }
   ],
   "source": [
    "# === Captum Integrated Gradients (recommended) ===\n",
    "# Paste and run in the notebook. Installs captum if missing, then runs IG for a small sample.\n",
    "import os, joblib, time, gc, numpy as np, traceback\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import captum\n",
    "    from captum.attr import IntegratedGradients\n",
    "except Exception:\n",
    "    print(\"Captum not found â€” installing captum...\")\n",
    "    !pip install captum --quiet\n",
    "    import importlib\n",
    "    importlib.reload(torch)\n",
    "    from captum.attr import IntegratedGradients\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# dims\n",
    "s_dim = X_train_static.shape[1]\n",
    "t_dim = X_train_temp.shape[1]\n",
    "c_dim = X_train_clin.shape[1]\n",
    "r_dim = X_train_rad.shape[1]\n",
    "D_concat = s_dim + t_dim + c_dim + r_dim\n",
    "print(\"Concatenated feature dim:\", D_concat)\n",
    "\n",
    "# Wrapper model: accepts concatenated tensor (B,D) and returns scalar probs (B,)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "def model_forward_concat_tensor(x_concat):\n",
    "    \"\"\"\n",
    "    x_concat: torch tensor (B, D_concat)\n",
    "    returns: torch.tensor (B,) probabilities\n",
    "    \"\"\"\n",
    "    # split\n",
    "    s = x_concat[:, :s_dim]\n",
    "    t = x_concat[:, s_dim:s_dim+t_dim]\n",
    "    c = x_concat[:, s_dim+t_dim:s_dim+t_dim+c_dim]\n",
    "    r = x_concat[:, s_dim+t_dim+c_dim:]\n",
    "    logits, _ = model(s.to(DEVICE), t.to(DEVICE), c.to(DEVICE), r.to(DEVICE))\n",
    "    return torch.sigmoid(logits)\n",
    "\n",
    "# Prepare background and explain samples (small)\n",
    "bg_size = min(30, X_train_static.shape[0])\n",
    "sample_size = min(20, X_test_static.shape[0])\n",
    "rng = np.random.RandomState(SEED if 'SEED' in globals() else 42)\n",
    "bg_idx = rng.choice(X_train_static.shape[0], bg_size, replace=False)\n",
    "sample_idx = rng.choice(X_test_static.shape[0], sample_size, replace=False)\n",
    "\n",
    "# Build concatenated numpy arrays\n",
    "X_train_concat = np.concatenate([X_train_static, X_train_temp, X_train_clin, X_train_rad], axis=1)\n",
    "X_test_concat  = np.concatenate([X_test_static, X_test_temp, X_test_clin, X_test_rad], axis=1)\n",
    "\n",
    "bg = torch.tensor(X_train_concat[bg_idx], dtype=torch.float32).to(DEVICE)\n",
    "X_explain = torch.tensor(X_test_concat[sample_idx], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "print(\"BG shape:\", bg.shape, \"Explain shape:\", X_explain.shape)\n",
    "\n",
    "# initialize IG\n",
    "ig = IntegratedGradients(model_forward_concat_tensor)\n",
    "\n",
    "# compute attributions (approx) per sample with baseline = background mean\n",
    "baseline = bg.mean(dim=0, keepdim=True)  # (1,D)\n",
    "attributions = []\n",
    "start = time.time()\n",
    "for i in range(X_explain.shape[0]):\n",
    "    x = X_explain[i:i+1]\n",
    "    try:\n",
    "        attr = ig.attribute(x, baselines=baseline, n_steps=50, internal_batch_size=1)\n",
    "        attributions.append(attr.detach().cpu().numpy().reshape(-1))\n",
    "    except Exception as e:\n",
    "        print(\"IG failed for sample\", i, \"error:\", e)\n",
    "        attributions.append(np.zeros((D_concat,), dtype=float))\n",
    "print(\"IG time (s):\", time.time()-start)\n",
    "\n",
    "attributions = np.stack(attributions, axis=0)  # (sample_count, D)\n",
    "# aggregate mean absolute\n",
    "mean_abs = np.mean(np.abs(attributions), axis=0)\n",
    "# feature names\n",
    "feat_names = []\n",
    "if len(numeric_static)>0: feat_names += numeric_static\n",
    "if 'X_train_cat' in globals() and X_train_cat.shape[1]>0:\n",
    "    feat_names += [f\"cat_{i}\" for i in range(X_train_cat.shape[1])]\n",
    "feat_names += [f\"temp_{i}\" for i in range(t_dim)]\n",
    "feat_names += [f\"clin_{i}\" for i in range(c_dim)]\n",
    "feat_names += [f\"rad_{i}\" for i in range(r_dim)]\n",
    "if len(feat_names) != D_concat:\n",
    "    feat_names = [f\"feat_{i}\" for i in range(D_concat)]\n",
    "\n",
    "# Save outputs\n",
    "outpath = os.path.join(EXPLAIN_DIR, f\"captum_ig_{WINDOW}.pkl\")\n",
    "joblib.dump({'attributions': attributions, 'mean_abs': mean_abs, 'feat_names': feat_names, 'sample_idx': sample_idx}, outpath)\n",
    "print(\"Saved Captum IG outputs to:\", outpath)\n",
    "\n",
    "# Plot topk\n",
    "topk = min(30, len(mean_abs))\n",
    "idxs = np.argsort(-mean_abs)[:topk]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, max(4, topk*0.22)))\n",
    "plt.barh([feat_names[i] for i in idxs[::-1]], mean_abs[idxs][::-1])\n",
    "plt.title(\"Top mean |IntegratedGradients|\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPLAIN_DIR, f\"captum_ig_top{topk}_{WINDOW}.png\"), bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8631483,
     "sourceId": 13585812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
